# ============================================================================
# SARK Production Configuration Template
# ============================================================================
# This file contains all environment variables required for SARK deployment.
# Copy this file to .env and customize for your environment.
#
# SECURITY WARNING:
# - Never commit .env files with real credentials to version control
# - All default passwords MUST be changed in production
# - Use secrets management (HashiCorp Vault, AWS Secrets Manager, etc.)
# - Minimum secret_key length: 32 characters
# ============================================================================

# ============================================================================
# APPLICATION SETTINGS
# ============================================================================

# Environment: development, staging, or production
# This controls security features (HSTS, debug mode, etc.)
ENVIRONMENT=production

# Application identification
APP_NAME=SARK
APP_VERSION=0.1.0

# Debug mode - MUST be false in production
DEBUG=false

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Production recommendation: INFO or WARNING
LOG_LEVEL=INFO

# ============================================================================
# API SERVER CONFIGURATION
# ============================================================================

# API server binding
# 0.0.0.0 allows external access (use firewall/reverse proxy for security)
# 127.0.0.1 for localhost-only access
API_HOST=0.0.0.0
API_PORT=8000

# Number of Uvicorn worker processes
# Recommendation: (2 x CPU cores) + 1
API_WORKERS=4

# Auto-reload on code changes (development only)
# MUST be false in production
API_RELOAD=false

# ============================================================================
# SECURITY CONFIGURATION
# ============================================================================

# Secret key for JWT token signing and encryption
# CRITICAL: Generate a secure random string (minimum 32 characters)
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(48))"
SECRET_KEY=CHANGEME-generate-secure-random-key-minimum-32-characters

# JWT access token expiration (minutes)
# Shorter is more secure, but requires more frequent re-authentication
# Recommendation: 15-60 minutes
ACCESS_TOKEN_EXPIRE_MINUTES=15

# CORS allowed origins (comma-separated list)
# Restrict to your frontend domains only
# Examples:
#   - Single origin: https://app.example.com
#   - Multiple origins: https://app.example.com,https://admin.example.com
#   - Development: http://localhost:3000,http://localhost:3001
CORS_ORIGINS=https://your-frontend-domain.com

# ============================================================================
# POSTGRESQL DATABASE (Main Application Database)
# ============================================================================

# PostgreSQL connection settings
# Use hostname/IP for external database, or service name for Docker Compose
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=sark
POSTGRES_PASSWORD=CHANGEME-secure-postgres-password
POSTGRES_DB=sark

# Connection pool settings
# Recommendation: Adjust based on your workload and connection limits
# Pool size: Number of connections to maintain
# Max overflow: Additional connections allowed under load
POSTGRES_POOL_SIZE=20
POSTGRES_MAX_OVERFLOW=10

# ============================================================================
# TIMESCALEDB (Audit Event Database)
# ============================================================================
# TimescaleDB can be the same instance as PostgreSQL or a separate instance
# For high audit volume, use a dedicated TimescaleDB instance

# TimescaleDB connection settings
TIMESCALE_HOST=localhost
TIMESCALE_PORT=5432
TIMESCALE_USER=sark
TIMESCALE_PASSWORD=CHANGEME-secure-timescale-password
TIMESCALE_DB=sark_audit

# Examples:
# Shared instance (same as PostgreSQL):
#   TIMESCALE_HOST=localhost
#   TIMESCALE_PORT=5432
#   TIMESCALE_DB=sark_audit
#
# Dedicated instance:
#   TIMESCALE_HOST=timescale.example.com
#   TIMESCALE_PORT=5432
#   TIMESCALE_DB=sark_audit

# ============================================================================
# REDIS CACHE
# ============================================================================

# Valkey (Redis-compatible) connection settings
VALKEY_HOST=localhost
VALKEY_PORT=6379
VALKEY_PASSWORD=CHANGEME-secure-redis-password
VALKEY_DB=0

# Valkey (Redis-compatible) connection pool settings
# Recommendation: 50-200 based on concurrent request volume
VALKEY_POOL_SIZE=50

# ============================================================================
# CONSUL (Service Discovery)
# ============================================================================

# Consul server connection
CONSUL_HOST=localhost
CONSUL_PORT=8500
CONSUL_SCHEME=http

# Consul ACL token (required if ACLs are enabled)
# Leave empty if Consul ACLs are not enabled
CONSUL_TOKEN=

# Production example with ACLs:
#   CONSUL_HOST=consul.example.com
#   CONSUL_PORT=8500
#   CONSUL_SCHEME=https
#   CONSUL_TOKEN=your-consul-acl-token-here

# ============================================================================
# OPEN POLICY AGENT (OPA)
# ============================================================================

# OPA server URL and policy path
OPA_URL=http://localhost:8181
OPA_POLICY_PATH=/v1/data/mcp/allow

# OPA request timeout (seconds)
# Recommendation: 0.5-2.0 seconds for policy decisions
OPA_TIMEOUT_SECONDS=1.0

# Production example:
#   OPA_URL=https://opa.example.com
#   OPA_POLICY_PATH=/v1/data/mcp/production/allow
#   OPA_TIMEOUT_SECONDS=1.5

# ============================================================================
# HASHICORP VAULT (Secrets Management)
# ============================================================================

# Vault server URL
VAULT_URL=http://localhost:8200

# Vault authentication token
# SECURITY: Use AppRole or Kubernetes auth in production, not root tokens
VAULT_TOKEN=

# Vault namespace (Vault Enterprise only)
# Leave empty for Vault OSS
VAULT_NAMESPACE=

# Vault secrets mount point
# Default: "secret" for KV v2 secrets engine
VAULT_MOUNT_POINT=secret

# Production example (Vault Enterprise with AppRole):
#   VAULT_URL=https://vault.example.com
#   VAULT_TOKEN=  # Set via VAULT_ROLE_ID and VAULT_SECRET_ID instead
#   VAULT_NAMESPACE=engineering
#   VAULT_MOUNT_POINT=sark-secrets

# ============================================================================
# KAFKA (Optional - High-Scale Audit Pipeline)
# ============================================================================

# Enable Kafka for audit event streaming
# Recommended for deployments exceeding 50,000 events/minute
KAFKA_ENABLED=false

# Kafka bootstrap servers (comma-separated list)
# Format: host1:port1,host2:port2,host3:port3
KAFKA_BOOTSTRAP_SERVERS=localhost:9092

# Kafka topic configuration
KAFKA_AUDIT_TOPIC=sark-audit-events
KAFKA_CONSUMER_GROUP=sark-audit-consumers

# Production example (3-node Kafka cluster):
#   KAFKA_ENABLED=true
#   KAFKA_BOOTSTRAP_SERVERS=kafka1.example.com:9092,kafka2.example.com:9092,kafka3.example.com:9092
#   KAFKA_AUDIT_TOPIC=production-sark-audit
#   KAFKA_CONSUMER_GROUP=sark-production-consumers

# ============================================================================
# DISCOVERY SERVICE
# ============================================================================

# Discovery service scan interval (seconds)
# How often to scan for new MCP servers
# Recommendation: 300-900 (5-15 minutes)
DISCOVERY_INTERVAL_SECONDS=300

# Discovery methods (true/false)
DISCOVERY_NETWORK_SCAN_ENABLED=false
DISCOVERY_K8S_ENABLED=false
DISCOVERY_CLOUD_ENABLED=false

# Production example (Kubernetes discovery):
#   DISCOVERY_INTERVAL_SECONDS=600
#   DISCOVERY_NETWORK_SCAN_ENABLED=false
#   DISCOVERY_K8S_ENABLED=true
#   DISCOVERY_CLOUD_ENABLED=false

# ============================================================================
# AUDIT CONFIGURATION
# ============================================================================

# Audit event batching
# Batch size: Number of events to batch before sending
# Flush interval: Maximum seconds to wait before flushing partial batch
AUDIT_BATCH_SIZE=100
AUDIT_FLUSH_INTERVAL_SECONDS=5

# Audit data retention (days)
# Events older than this will be archived/deleted
# Recommendation: 90-365 days based on compliance requirements
AUDIT_RETENTION_DAYS=90

# ============================================================================
# SPLUNK SIEM INTEGRATION
# ============================================================================

# Enable Splunk integration
SPLUNK_ENABLED=false

# Splunk HTTP Event Collector (HEC) configuration
SPLUNK_HEC_URL=https://splunk.example.com:8088/services/collector
SPLUNK_HEC_TOKEN=

# Splunk indexing configuration
SPLUNK_INDEX=sark_audit
SPLUNK_SOURCETYPE=sark:audit:event
SPLUNK_SOURCE=sark

# Optional: Override hostname in Splunk events
# Leave empty to use system hostname
SPLUNK_HOST=

# Splunk SSL/TLS verification
# Recommendation: true in production (requires valid SSL certificate)
SPLUNK_VERIFY_SSL=true

# Splunk batching and retry configuration
SPLUNK_BATCH_SIZE=100
SPLUNK_BATCH_TIMEOUT_SECONDS=5
SPLUNK_RETRY_ATTEMPTS=3

# Production example:
#   SPLUNK_ENABLED=true
#   SPLUNK_HEC_URL=https://splunk-hec.example.com:8088/services/collector
#   SPLUNK_HEC_TOKEN=your-splunk-hec-token-uuid-format
#   SPLUNK_INDEX=production_sark_audit
#   SPLUNK_SOURCETYPE=sark:audit:event
#   SPLUNK_SOURCE=sark-production
#   SPLUNK_HOST=sark-app-01
#   SPLUNK_VERIFY_SSL=true
#   SPLUNK_BATCH_SIZE=500
#   SPLUNK_BATCH_TIMEOUT_SECONDS=10
#   SPLUNK_RETRY_ATTEMPTS=5

# ============================================================================
# DATADOG SIEM INTEGRATION
# ============================================================================

# Enable Datadog integration
DATADOG_ENABLED=false

# Datadog API credentials
# API Key: Required for sending logs
# App Key: Optional, used for advanced features
DATADOG_API_KEY=
DATADOG_APP_KEY=

# Datadog site selection
# Options: datadoghq.com (US1), datadoghq.eu (EU), us3.datadoghq.com (US3),
#          us5.datadoghq.com (US5), ap1.datadoghq.com (AP1), ddog-gov.com (US1-FED)
DATADOG_SITE=datadoghq.com

# Datadog tagging
DATADOG_SERVICE=sark
DATADOG_ENVIRONMENT=production

# Optional: Override hostname in Datadog logs
# Leave empty to use system hostname
DATADOG_HOSTNAME=

# Datadog SSL/TLS verification
# Recommendation: true in production
DATADOG_VERIFY_SSL=true

# Datadog batching and retry configuration
DATADOG_BATCH_SIZE=100
DATADOG_BATCH_TIMEOUT_SECONDS=5
DATADOG_RETRY_ATTEMPTS=3

# Production example:
#   DATADOG_ENABLED=true
#   DATADOG_API_KEY=your-datadog-api-key-here
#   DATADOG_APP_KEY=your-datadog-app-key-here
#   DATADOG_SITE=datadoghq.com
#   DATADOG_SERVICE=sark
#   DATADOG_ENVIRONMENT=production
#   DATADOG_HOSTNAME=sark-app-01
#   DATADOG_VERIFY_SSL=true
#   DATADOG_BATCH_SIZE=500
#   DATADOG_BATCH_TIMEOUT_SECONDS=10
#   DATADOG_RETRY_ATTEMPTS=5

# ============================================================================
# OBSERVABILITY
# ============================================================================

# Prometheus metrics
METRICS_ENABLED=true
METRICS_PORT=9090

# Distributed tracing (OpenTelemetry)
TRACING_ENABLED=false
TRACING_ENDPOINT=

# Production example (Jaeger tracing):
#   TRACING_ENABLED=true
#   TRACING_ENDPOINT=http://jaeger-collector.example.com:14268/api/traces

# ============================================================================
# PRODUCTION DEPLOYMENT EXAMPLES
# ============================================================================

# Example 1: Full Production Setup with Splunk
# -----------------------------------------------------------------------------
# ENVIRONMENT=production
# DEBUG=false
# LOG_LEVEL=INFO
# SECRET_KEY=<generated-secure-key-48-chars-minimum>
# ACCESS_TOKEN_EXPIRE_MINUTES=30
# CORS_ORIGINS=https://sark.example.com
#
# POSTGRES_HOST=postgres.example.com
# POSTGRES_PORT=5432
# POSTGRES_PASSWORD=<secure-password>
# TIMESCALE_HOST=timescale.example.com
# TIMESCALE_PASSWORD=<secure-password>
# VALKEY_HOST=valkey.example.com
# VALKEY_PASSWORD=<secure-password>
#
# SPLUNK_ENABLED=true
# SPLUNK_HEC_URL=https://splunk.example.com:8088/services/collector
# SPLUNK_HEC_TOKEN=<splunk-hec-token>
# SPLUNK_INDEX=production_sark_audit

# Example 2: Production with Datadog and Kafka
# -----------------------------------------------------------------------------
# ENVIRONMENT=production
# DEBUG=false
# LOG_LEVEL=WARNING
# SECRET_KEY=<generated-secure-key-48-chars-minimum>
#
# KAFKA_ENABLED=true
# KAFKA_BOOTSTRAP_SERVERS=kafka1.example.com:9092,kafka2.example.com:9092,kafka3.example.com:9092
#
# DATADOG_ENABLED=true
# DATADOG_API_KEY=<datadog-api-key>
# DATADOG_SITE=datadoghq.com
# DATADOG_ENVIRONMENT=production

# Example 3: Kubernetes Production Deployment
# -----------------------------------------------------------------------------
# ENVIRONMENT=production
# DEBUG=false
# LOG_LEVEL=INFO
#
# # Use Kubernetes service names for internal services
# POSTGRES_HOST=postgres-service.database.svc.cluster.local
# VALKEY_HOST=redis-service.cache.svc.cluster.local
# CONSUL_HOST=consul-service.consul.svc.cluster.local
# OPA_URL=http://opa-service.opa.svc.cluster.local:8181
#
# # Use Kubernetes secrets for sensitive values (mounted as env vars)
# SECRET_KEY=${KUBERNETES_SECRET_KEY}
# POSTGRES_PASSWORD=${KUBERNETES_POSTGRES_PASSWORD}
# VALKEY_PASSWORD=${KUBERNETES_VALKEY_PASSWORD}
# SPLUNK_HEC_TOKEN=${KUBERNETES_SPLUNK_TOKEN}
#
# DISCOVERY_K8S_ENABLED=true
# SPLUNK_ENABLED=true

# ============================================================================
# SECRETS MANAGEMENT BEST PRACTICES
# ============================================================================
#
# 1. NEVER commit real secrets to version control
#    - Use .env.production.example as template only
#    - Add .env* to .gitignore
#
# 2. Use dedicated secrets management solutions:
#    - HashiCorp Vault (recommended for enterprise)
#    - AWS Secrets Manager (AWS deployments)
#    - Azure Key Vault (Azure deployments)
#    - GCP Secret Manager (GCP deployments)
#    - Kubernetes Secrets (Kubernetes deployments)
#
# 3. Rotate secrets regularly:
#    - Database passwords: 90 days
#    - API tokens: 30-90 days
#    - JWT secret_key: 180 days
#
# 4. Use strong passwords:
#    - Minimum 20 characters
#    - Mix of uppercase, lowercase, numbers, symbols
#    - Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
#
# 5. Restrict access:
#    - Use principle of least privilege
#    - Separate credentials per environment (dev/staging/prod)
#    - Audit secret access regularly
#
# 6. Environment-specific secrets:
#    - Development: .env.development
#    - Staging: .env.staging
#    - Production: .env.production (or external secrets manager)
#
# ============================================================================
